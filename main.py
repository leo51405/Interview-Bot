import google.generativeai as genai
from typing import List

# Set up Gemini API key
GOOGLE_API_KEY = "AIzaSyD8d8foqTNUDIn4COLFnFre-cDkWdWbWdI"
genai.configure(api_key=GOOGLE_API_KEY)
model = genai.GenerativeModel('models/gemini-1.5-flash')

# é¡Œåº«ä½œç‚ºé¢¨æ ¼ç¤ºç¯„è³‡æ–™åº«
QUESTION_BANK = {
    "è³‡æ–™ç§‘å­¸å®¶": {
        "ç¹é«”ä¸­æ–‡": [
            "è«‹è§£é‡‹ bias-variance tradeoff æ˜¯ä»€éº¼?å®ƒç‚ºä½•é‡è¦?",
            "å‡è¨­ä½ åœ¨è™•ç†ä¸€å€‹é«˜åº¦ä¸å¹³è¡¡çš„åˆ†é¡å•é¡Œï¼Œä½ æœƒæ¡ç”¨å“ªäº›ç­–ç•¥?",
            "ä»€éº¼æƒ…æ³ä¸‹ä½ æœƒé¸æ“‡ä½¿ç”¨éš¨æ©Ÿæ£®æ—è€Œä¸æ˜¯é‚è¼¯å›æ­¸?",
            "è«‹æè¿°ä½ éå»å¦‚ä½•ä½¿ç”¨è³‡æ–™ä¾†é©…å‹•æ¥­å‹™æ±ºç­–çš„æ¡ˆä¾‹ã€‚",
            "ä½ å¦‚ä½•è©•ä¼°ä¸€å€‹é æ¸¬æ¨¡å‹æ˜¯å¦é©åˆå¯¦éš›éƒ¨ç½²?",
            "å¦‚æœä½ çš„æ¨¡å‹æº–ç¢ºç‡ç‚º 95%ï¼Œä½ æ€éº¼èªªæœè€é—†å®ƒé‚„ä¸å¤ å¥½?",
            "è«‹è§£é‡‹ A/B test èˆ‡å¤šè®Šé‡æ¸¬è©¦çš„å·®ç•°ã€‚",
            "å¦‚ä½•è™•ç†æœ‰è¨±å¤šç¼ºå¤±å€¼èˆ‡ç•°å¸¸å€¼çš„è³‡æ–™é›†?è«‹èˆ‰ä¾‹ã€‚",
            "ä½ é‡éè³‡æ–™åèª¤(data bias)å—?æ˜¯æ€éº¼ç™¼ç¾ä¸¦ä¿®æ­£çš„?",
            "ç•¶ä½ çš„æ¨¡å‹åœ¨ training è¡¨ç¾è‰¯å¥½ä½†åœ¨ production å‡ºç¾å•é¡Œæ™‚ï¼Œä½ æœƒæ€éº¼è™•ç†?"
        ],
        "è‹±æ–‡": [
            "Please explain what the bias-variance tradeoff is and why it matters.",
            "Suppose you're dealing with a highly imbalanced classification problem. What strategies would you use?",
            "In what situations would you choose random forest over logistic regression?",
            "Describe a case where you used data to drive a business decision.",
            "How do you evaluate whether a predictive model is ready for deployment?",
            "If your model has 95% accuracy, how would you convince your boss that itâ€™s not good enough?",
            "Explain the difference between A/B testing and multivariate testing.",
            "How do you handle datasets with many missing or anomalous values? Give an example.",
            "Have you ever encountered data bias? How did you detect and correct it?",
            "If your model performs well in training but poorly in production, what steps would you take?"
        ]
    },
    "æ•¸æ“šåˆ†æå¸«": {
        "ç¹é«”ä¸­æ–‡": [
            "è«‹æè¿°ä½ éå»å¦‚ä½•é‹ç”¨ SQL å¾å¤§å‹è³‡æ–™åº«ä¸­æ“·å–é‡è¦è³‡è¨Šã€‚",
            "ä»€éº¼æ˜¯ cohort analysis?åœ¨ä»€éº¼å ´æ™¯ä¸‹æœƒä½¿ç”¨å®ƒ?",
            "ä½ æœƒå¦‚ä½•è™•ç†ä¸€å€‹å……æ»¿é¡åˆ¥å‹è®Šæ•¸çš„è³‡æ–™é›†?",
            "ä½ æ›¾ç¶“åšéå“ªäº›å„€è¡¨æ¿?ä½ å¦‚ä½•æ±ºå®š KPI å‘ˆç¾æ–¹å¼?",
            "å‡è¨­æŸç”¢å“éŠ·å”®ä¸‹æ»‘ï¼Œä½ æœƒæ€éº¼ç”¨è³‡æ–™ä¾†æ‰¾å‡ºåŸå› ?",
            "åœ¨è™•ç†æ™‚é–“åºåˆ—è³‡æ–™æ™‚ï¼Œæœƒæ³¨æ„å“ªäº›é™·é˜±?",
            "ä½ æ€éº¼è§£é‡‹ p-value?å®ƒåœ¨ A/B test ä¸­çš„è§’è‰²æ˜¯ä»€éº¼?",
            "ç•¶è€é—†è¦æ±‚æ˜å¤©äº¤å‡ºæ•¸æ“šå ±å‘Šï¼Œä½†ä½ è³‡æ–™é‚„ä¸å®Œæ•´æ™‚æ€éº¼è¾¦?",
            "æ€éº¼å¾åŸå§‹è³‡æ–™è½‰åŒ–å‡ºæœ‰æ´è¦‹çš„å•†æ¥­åˆ†æ?è«‹èˆ‰ä¾‹ã€‚",
            "ä½ é‡éæœ€é›£è™•ç†çš„é«’è³‡æ–™æ˜¯ä»€éº¼?ä½ æ˜¯å¦‚ä½•æ¸…ç†çš„?"
        ],
        "è‹±æ–‡": [
            "Describe how you've used SQL to extract insights from a large database.",
            "What is cohort analysis, and in what scenario would you use it?",
            "How would you handle a dataset with many categorical variables?",
            "What dashboards have you built, and how did you decide which KPIs to show?",
            "Suppose product sales are decliningâ€”how would you use data to find out why?",
            "What are the common pitfalls in working with time series data?",
            "How do you explain the concept of a p-value, and what role does it play in A/B testing?",
            "What would you do if your boss asked for a report tomorrow but the data is incomplete?",
            "How do you convert raw data into business insights? Please give an example.",
            "Describe the most difficult dirty data you've encountered and how you cleaned it."
        ]
    },
    "æ©Ÿå™¨å­¸ç¿’å·¥ç¨‹å¸«": {
        "ç¹é«”ä¸­æ–‡": [
            "è«‹èªªæ˜ä½ å° model deployment çš„ç¶“é©—èˆ‡æµç¨‹ã€‚",
            "åœ¨é¸æ“‡ç¥ç¶“ç¶²çµ¡æ¶æ§‹æ™‚ï¼Œä½ é€šå¸¸è€ƒé‡å“ªäº›å› ç´ ?",
            "è«‹è§£é‡‹ batch size çš„é¸æ“‡æœƒå¦‚ä½•å½±éŸ¿è¨“ç·´éç¨‹ã€‚",
            "ä½ æ˜¯å¦‚ä½•è™•ç†æ¨¡å‹éæ“¬åˆå•é¡Œçš„?",
            "å¦‚ä½•è©•ä¼°æ¨¡å‹ drift?ä½ æœ‰å“ªäº›ç›£æ§ç­–ç•¥?",
            "ç•¶éœ€è¦è™•ç†æ•¸ç™¾è¬ç­†è³‡æ–™é€²è¡Œæ¨¡å‹è¨“ç·´ï¼Œä½ æœƒæ€éº¼åš?",
            "è«‹è§£é‡‹ä»€éº¼æ˜¯ transfer learning?ä»€éº¼æƒ…æ³é©åˆä½¿ç”¨?",
            "è«‹èªªæ˜åœ¨å¯¦å‹™ä¸Šä½¿ç”¨éçš„ CI/CD å·¥å…·ä¾†éƒ¨ç½²æ¨¡å‹çš„ç¶“é©—ã€‚",
            "ä½ æœ‰å¯¦ä½œéæ¨è–¦ç³»çµ±å—?è«‹èªªæ˜æ¶æ§‹èˆ‡æ¼”ç®—æ³•é¸æ“‡ã€‚",
            "åœ¨è™•ç†èªéŸ³/å½±åƒ/æ™‚é–“åºåˆ—è³‡æ–™æ™‚ï¼Œæ¨¡å‹è¨­è¨ˆæœ‰ä½•ä¸åŒ?"
        ],
        "è‹±æ–‡": [
            "Describe your experience with model deployment and the steps involved.",
            "What factors do you usually consider when choosing a neural network architecture?",
            "How does the choice of batch size affect the training process?",
            "How do you handle model overfitting?",
            "How do you detect and respond to model drift? What monitoring strategies do you use?",
            "How would you handle training a model with millions of records?",
            "What is transfer learning, and when is it appropriate to use?",
            "Explain your experience using CI/CD tools to deploy models in production.",
            "Have you implemented a recommendation system? Describe its architecture and algorithm choices.",
            "How does model design differ when working with audio, image, or time series data?"
        ]
    },
    "é€šç”¨": {
        "ç¹é«”ä¸­æ–‡": [
            "ä½ ç‚ºä»€éº¼æƒ³åŠ å…¥æˆ‘å€‘å…¬å¸?",
            "ä½ è¦ºå¾—ä½ æœ€å¤§çš„å„ªé»èˆ‡ç¼ºé»æ˜¯ä»€éº¼?",
            "ç•¶ä½ å’ŒåŒäº‹æ„è¦‹ä¸åˆæ™‚ä½ æœƒæ€éº¼åš?",
            "æè¿°ä½ é¢å°å›°é›£ä»»å‹™æ™‚çš„è™•ç†æ–¹å¼ã€‚",
            "ä½ å¦‚ä½•å®‰æ’å·¥ä½œå„ªå…ˆé †åº?",
            "ä½ æœ€æŒ«æŠ˜çš„ä¸€æ¬¡ç¶“é©—æ˜¯ä»€éº¼?",
            "åœ¨ä¸Šä¸€ä»½å·¥ä½œä¸­ï¼Œä½ ä¸»è¦è² è²¬ä»€éº¼å·¥ä½œ?ï¼æœ€æœ‰æˆå°±æ„Ÿçš„äº‹æ˜¯ä»€éº¼?",
            "ä½ é›¢é–‹ä¸Šä¸€ä»½å·¥ä½œçš„åŸå› æ˜¯ä»€éº¼?",
            "ç¢°åˆ°å®Œå…¨æ²’æ¥è§¸éçš„é ˜åŸŸæ™‚ï¼Œä½ æœƒæ€éº¼åš?",
            "æ¯”èµ·åˆ¥äººï¼Œä½ çš„å„ªå‹¢æ˜¯ä»€éº¼?"
        ],
        "è‹±æ–‡": [
            "Why do you want to join our company?",
            "What are your greatest strengths and weaknesses?",
            "How do you handle disagreements with colleagues?",
            "Describe how you handle a difficult or challenging task.",
            "How do you prioritize your tasks at work?",
            "What was your most frustrating experience?",
            "What were your main responsibilities in your last job, and what are you most proud of?",
            "Why did you leave your last job?",
            "What would you do when facing a domain you've never worked in before?",
            "Compared to others, what is your biggest advantage?"
        ]
    }
}

def build_prompt(job_title: str, language: str) -> str:
    examples = QUESTION_BANK.get(job_title, QUESTION_BANK["é€šç”¨"])
    example_block = "\n".join(examples)
    return (
        f"ä½ æ˜¯ä¸€ä½è³‡æ·±é¢è©¦å®˜ï¼Œæ­£åœ¨é¢è©¦ä¸€ä½æ‡‰å¾µ {job_title} çš„å€™é¸äººã€‚\n"
        f"ä»¥ä¸‹æ˜¯ä½ å‡ºé¡Œé¢¨æ ¼çš„ç¯„ä¾‹é¡Œ:\n{example_block}\n\n"
        f"è«‹ä¾ç…§ç›¸åŒé¢¨æ ¼å†å‡º 3 é¡Œï¼Œ"
        f"æ¯å€‹å•é¡Œæœ€å¤šå…©è¡Œï¼Œè«‹ç”¨ {language} å‘ˆç¾ï¼Œ"
        f"ä¸è¦çµ¦å‡ºç­”æ¡ˆæˆ–è§£é‡‹ã€‚"
    )

def generate_questions(job_title: str, language: str) -> str:
    prompt = build_prompt(job_title, language)
    response = model.generate_content(prompt)
    raw = response.text.strip()

    lines = [line.strip() for line in raw.splitlines() if line.strip()]
    # return "\n".join(lines)
    return lines


def build_feedback_prompt(question: str, answer: str, language: str = "ç¹é«”ä¸­æ–‡") -> str:
    return (
        f"ä½ æ˜¯ä¸€ä½è³‡æ·±é¢è©¦å®˜ï¼Œæ­£åœ¨é€²è¡Œæ¨¡æ“¬é¢è©¦ã€‚\n"
        f"ä»¥ä¸‹æ˜¯æ‡‰å¾µè€…çš„ä½œç­”å…§å®¹ï¼Œè«‹é‡å°é€™å€‹å•é¡Œé€²è¡Œå›é¥‹:\n\n"
        f"å•é¡Œ:{question}\n"
        f"å›ç­”:{answer}\n\n"
        f"è«‹å¾ä¸‰å€‹é¢å‘é€²è¡Œè©•åˆ†(æ¯é … 1~5 åˆ†):\n"
        f"1. æŠ€è¡“æ·±åº¦\n"
        f"2. è¡¨é”æ¸…æ™°åº¦\n"
        f"3. å•é¡Œç†è§£èƒ½åŠ›\n\n"        
        f"è«‹ç”¨ {language} å›è¦†ï¼Œä¸¦ä¸”ç¸½çµå»ºè­°é™åˆ¶100å­—å…§ï¼Œæ ¼å¼å¦‚ä¸‹:\n"
        f"æŠ€è¡“æ·±åº¦:Xåˆ†\n"
        f"è¡¨é”æ¸…æ™°åº¦:Xåˆ†\n"
        f"å•é¡Œç†è§£èƒ½åŠ›:Xåˆ†\n"
        f"ç¸½çµå»ºè­°:......"
        f"è«‹åš´æ ¼éµå¾ä¸Šé¢çš„æ ¼å¼ã€‚"
    )

def evaluate_answer(question: str, user_answer: str, language: str = "ç¹é«”ä¸­æ–‡") -> str:
    prompt = build_feedback_prompt(question, user_answer, language)
    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        return f"âš ï¸ GPT å›æ‡‰å¤±æ•—ï¼š{e}"


# æ¸¬è©¦è¼¸å‡º
def interview_round(question: str, language: str = "ç¹é«”ä¸­æ–‡") -> dict:
    print(f"å•é¡Œ:{question}")
    user_answer = input("è«‹è¼¸å…¥ä½ çš„å›ç­”:\n")
    feedback = evaluate_answer(question, user_answer, language)
    return {
        "question": question,
        "answer": user_answer,
        "feedback": feedback
    }

# æ¸¬è©¦è¼¸å‡º
def interview_session(job_title: str, language: str = "ç¹é«”ä¸­æ–‡", num_questions: int = 3):
    questions = generate_questions(job_title, language)
    print(f"ğŸ¯ æ¨¡æ“¬é¢è©¦é–‹å§‹ï¼š{job_title}ï¼ˆå…± {num_questions} é¡Œï¼‰\n")
    results = []
    for i in range(min(num_questions, len(questions))):
        print(f"\n--- ç¬¬ {i+1} é¡Œ ---")
        result = interview_round(questions[i], language)
        print("\nğŸ“ GPT å›é¥‹ï¼š")
        print(result["feedback"])
        results.append(result)
    print("\nâœ… æ¨¡æ“¬é¢è©¦çµæŸï¼\n")
    return results

# ä¸»ç¨‹å¼å•Ÿå‹•é»
if __name__ == "__main__":
    job = input("è«‹è¼¸å…¥è·ç¼ºåç¨±ï¼ˆä¾‹å¦‚ï¼šè³‡æ–™ç§‘å­¸å®¶ï¼‰ï¼š")
    lang = input("è«‹é¸æ“‡èªè¨€ï¼ˆä¾‹å¦‚ï¼šç¹é«”ä¸­æ–‡ æˆ– è‹±æ–‡ï¼‰ï¼š")
    interview_session(job, language=lang, num_questions=2)
